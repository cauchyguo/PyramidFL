2023-09-21:17:54:15,310 INFO     [param_server.py:13] End up with cuda device tensor([0.9559], device='cuda:0')
2023-09-21:17:54:15,773 INFO     [param_server.py:616] ====Start to initialize dataset
2023-09-21:17:54:15,773 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:17:54:45,200 INFO     [learner.py:13] End up with cuda device tensor([0.0302], device='cuda:1')
2023-09-21:17:54:45,200 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:17:54:45,254 INFO     [learner.py:13] End up with cuda device tensor([0.0898], device='cuda:3')
2023-09-21:17:54:45,254 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:17:54:45,288 INFO     [learner.py:13] End up with cuda device tensor([0.7198], device='cuda:2')
2023-09-21:17:54:45,288 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:17:54:45,653 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:17:54:45,653 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:17:54:45,705 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:17:54:45,705 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:17:54:45,740 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:17:54:45,741 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:17:54:48,326 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-21:17:54:48,568 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-21:17:54:48,671 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-21:17:54:48,681 INFO     [distributed_c10d.py:354] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:17:54:48,681 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:17:54:48,682 INFO     [distributed_c10d.py:354] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:17:54:48,682 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:17:54:48,683 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-21:17:54:48,684 INFO     [distributed_c10d.py:354] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:17:54:48,684 INFO     [distributed_c10d.py:354] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:17:54:48,684 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:17:54:48,707 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.02515864372253418 s

2023-09-21:17:54:48,707 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:17:54:48,722 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.039544105529785156 s

2023-09-21:17:54:48,722 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:17:54:48,723 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.03887152671813965 s

2023-09-21:17:54:48,724 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:17:54:51,290 INFO     [param_server.py:98] ====Info of all feasible clients {'total_feasible_clients': 491, 'total_length': 33443}
2023-09-21:17:54:51,553 INFO     [param_server.py:197] ====PS: get in run()
2023-09-21:17:54:51,553 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:17:54:51,554 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0003256797790527344 s

2023-09-21:17:54:51,554 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:17:54:51,555 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:17:54:51,557 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:17:54:51,557 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:17:54:51,559 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:17:54:51,572 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:17:54:51,572 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:17:54:51,573 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0005934238433837891 s

2023-09-21:17:54:51,573 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:17:54:51,573 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0003490447998046875 s

2023-09-21:17:54:51,574 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:17:54:51,574 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:17:54:51,574 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:17:54:51,577 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:17:54:51,577 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:17:54:51,577 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:17:54:51,577 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:17:54:51,580 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:17:54:51,581 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:17:54:51,638 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=1, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=8045, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='43295', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0921_175410_15585', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:17:54:51,662 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=2, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=8045, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='43295', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=2, threads=4, time_stamp='0921_175410_15585', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:17:54:51,673 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=3, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=8045, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='43295', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=3, threads=4, time_stamp='0921_175410_15585', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:17:54:51,866 INFO     [learner.py:526] ====Start train round 1
2023-09-21:17:54:51,882 INFO     [learner.py:526] ====Start train round 1
2023-09-21:17:54:51,898 INFO     [learner.py:526] ====Start train round 1
2023-09-21:17:54:52,34 INFO     [learner.py:164] Start to run client 1 on rank 1...
====Worker: init_myprocesses
Begin!
2023-09-21:17:54:52,43 INFO     [learner.py:164] Start to run client 2 on rank 2...
====Worker: init_myprocesses
Begin!
2023-09-21:17:54:52,59 INFO     [learner.py:164] Start to run client 6 on rank 3...
====Worker: init_myprocesses
Begin!
2023-09-21:17:54:55,257 INFO     [learner.py:437] ====Failed to run client 2
2023-09-21:17:54:55,258 INFO     [learner.py:439] Completed to run client 2
2023-09-21:17:54:55,258 INFO     [learner.py:606] ====Pushing takes 0.00044226646423339844 s
2023-09-21:17:54:55,259 INFO     [param_server.py:298] ====Start to merge models
2023-09-21:17:54:55,259 INFO     [learner.py:437] ====Failed to run client 1
2023-09-21:17:54:55,259 INFO     [param_server.py:364] ====Done handling rank 2, with ratio 0, now collected 0 clients
2023-09-21:17:54:55,260 INFO     [learner.py:439] Completed to run client 1
2023-09-21:17:54:55,260 INFO     [param_server.py:418] Lock worker 2 with localStep 1 , while globalStep is 0

2023-09-21:17:54:55,260 INFO     [learner.py:606] ====Pushing takes 0.00033211708068847656 s
2023-09-21:17:54:55,260 INFO     [param_server.py:298] ====Start to merge models
2023-09-21:17:54:55,261 INFO     [param_server.py:364] ====Done handling rank 1, with ratio 0, now collected 0 clients
2023-09-21:17:54:55,261 INFO     [param_server.py:418] Lock worker 1 with localStep 1 , while globalStep is 0

2023-09-21:17:54:55,278 INFO     [learner.py:437] ====Failed to run client 6
2023-09-21:17:54:55,279 INFO     [learner.py:439] Completed to run client 6
2023-09-21:17:54:55,279 INFO     [learner.py:606] ====Pushing takes 0.000293731689453125 s
2023-09-21:17:54:55,280 INFO     [param_server.py:298] ====Start to merge models
2023-09-21:17:54:55,280 INFO     [param_server.py:364] ====Done handling rank 3, with ratio 0, now collected 0 clients
2023-09-21:17:54:55,280 INFO     [param_server.py:389] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 3.0
2023-09-21:17:54:55,280 INFO     [param_server.py:418] Lock worker 3 with localStep 1 , while globalStep is 1

2023-09-21:17:54:55,280 INFO     [param_server.py:449] ====Epoch 2 completes 0 clients with loss 0, sampled rewards are: 
 {} 
==========
2023-09-21:17:54:55,280 INFO     [param_server.py:458] ====Start to sample for epoch 2, global virtualClock: 0.0, round_duration: 0.0
2023-09-21:17:54:55,285 INFO     [param_server.py:475] ====Try to resample clients, final takes: 
 [1286, 38, 1835, 189, 1315, 348, 831, 140, 1510, 584]
2023-09-21:17:54:56,225 INFO     [param_server.py:575] ====Error: list index out of range, <class 'IndexError'>, param_server.py, 535
====Error: list index out of range

Traceback (most recent call last):
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 624, in <module>
    q, param_q, stop_signal, run, args.backend
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 130, in init_myprocesses
    fn(model, queue, param_q, stop_signal, clientSampler)
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 273, in run
    if not queue.empty():
  File "<string>", line 2, in empty
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/managers.py", line 818, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/reduction.py", line 51, in dumps
    cls(buf, protocol).dump(obj)
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/reduction.py", line 41, in __init__
    self.dispatch_table.update(self._extra_reducers)
KeyboardInterrupt
