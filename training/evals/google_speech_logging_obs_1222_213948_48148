/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-12-22:21:39:54,626 INFO     [param_server.py:13] End up with cuda device tensor([0.5578], device='cuda:0')
2021-12-22:21:39:55,47 INFO     [param_server.py:616] ====Start to initialize dataset
2021-12-22:21:39:55,49 INFO     [flLibs.py:59] ====Initialize the model
/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2021-12-22:21:40:24,223 INFO     [learner.py:13] End up with cuda device tensor([0.6282], device='cuda:1')
2021-12-22:21:40:24,228 INFO     [learner.py:41] ===== Experiment start on : dev-amd20-v100=====
2021-12-22:21:40:24,645 INFO     [learner.py:709] ====Start to initialize dataset
2021-12-22:21:40:24,646 INFO     [flLibs.py:59] ====Initialize the model
2021-12-22:21:40:25,735 INFO     [learner.py:732] ==== Starting training data partitioner =====
2021-12-22:21:40:25,752 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.015682697296142578 s

2021-12-22:21:40:25,753 INFO     [learner.py:735] ==== Finished training data partitioner =====
2021-12-22:21:40:26,108 INFO     [learner.py:88] ====Save obs_client====
2021-12-22:21:40:27,68 INFO     [param_server.py:98] ====Info of all feasible clients {'total_feasible_clients': 491, 'total_length': 33443}
2021-12-22:21:40:27,85 INFO     [param_server.py:105] ====Save obs_client====
2021-12-22:21:40:27,656 INFO     [param_server.py:197] ====PS: get in run()
2021-12-22:21:40:27,656 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2021-12-22:21:40:27,658 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0008511543273925781 s

2021-12-22:21:40:27,659 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2021-12-22:21:40:27,662 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2021-12-22:21:40:27,668 INFO     [divide_data.py:509] Raw class per worker is : array([[ 74.,  70.,  93.,  90.,  71.,  98., 112.,  61., 101., 105.,  73.,
         92.,  86.,  57.,  49., 102.,  47.,  39.,  93.,  75.]])

2021-12-22:21:40:27,669 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2021-12-22:21:40:27,675 INFO     [learner.py:445] ====Worker: Start running
2021-12-22:21:40:27,718 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech', data_mapfile='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/google_speech/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=True, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=2, eval_all_checkpoints=False, eval_data_file='', eval_interval=20, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=1, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/mnt/home/lichenni/projects/mobicom22_fl/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=54513, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='dev-amd20-v100', ps_port='43939', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='1222_213948_48148', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=5, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/mnt/ufs18/nodr/home/lichenni/projects/FedScale/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2021-12-22:21:40:27,916 INFO     [learner.py:526] ====Start train round 1
2021-12-22:21:40:28,51 INFO     [learner.py:164] Start to run client 1 on rank 1...
====Worker: init_myprocesses
Begin!
2021-12-22:21:40:30,584 INFO     [learner.py:439] Completed to run client 1
2021-12-22:21:40:30,986 INFO     [learner.py:606] ====Pushing takes 0.40027832984924316 s
2021-12-22:21:40:31,850 INFO     [param_server.py:298] ====Start to merge models
2021-12-22:21:40:32,27 INFO     [param_server.py:364] ====Done handling rank 1, with ratio 1.0, now collected 1 clients
2021-12-22:21:40:32,28 INFO     [param_server.py:389] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 1.0
2021-12-22:21:40:32,32 INFO     [param_server.py:418] Lock worker 1 with localStep 1 , while globalStep is 1

2021-12-22:21:40:32,32 INFO     [param_server.py:449] ====Epoch 2 completes 1 clients with loss 15.881352565404862, sampled rewards are: 
 {1: 0.03656559556839151} 
==========
2021-12-22:21:40:32,33 INFO     [param_server.py:458] ====Start to sample for epoch 2, global virtualClock: 0.0, round_duration: 0.0
2021-12-22:21:40:32,36 INFO     [param_server.py:475] ====Try to resample clients, final takes: 
 [1286, 38, 140, 501, 320]
2021-12-22:21:40:32,748 INFO     [param_server.py:568] Epoch is done: 2
2021-12-22:21:40:32,750 INFO     [learner.py:667] ====Dump model successfully
2021-12-22:21:40:32,985 INFO     [learner.py:526] ====Start train round 2
2021-12-22:21:40:33,97 INFO     [learner.py:164] Start to run client 1286 on rank 1...
2021-12-22:21:40:34,954 INFO     [learner.py:439] Completed to run client 1286
2021-12-22:21:40:35,89 INFO     [learner.py:164] Start to run client 38 on rank 1...
2021-12-22:21:40:36,959 INFO     [learner.py:439] Completed to run client 38
2021-12-22:21:40:37,121 INFO     [learner.py:164] Start to run client 140 on rank 1...
2021-12-22:21:40:39,432 INFO     [learner.py:439] Completed to run client 140
2021-12-22:21:40:39,596 INFO     [learner.py:164] Start to run client 501 on rank 1...
2021-12-22:21:40:42,118 INFO     [learner.py:439] Completed to run client 501
2021-12-22:21:40:42,267 INFO     [learner.py:164] Start to run client 320 on rank 1...
2021-12-22:21:40:44,575 INFO     [learner.py:439] Completed to run client 320
2021-12-22:21:40:45,518 INFO     [learner.py:673] ====Error: [Errno 32] Broken pipe, <class 'BrokenPipeError'>, learner.py, 602
Traceback (most recent call last):
  File "/mnt/home/lichenni/projects/mobicom22_fl/training/learner.py", line 769, in <module>
    run, args.backend, client_cfg)
  File "/mnt/home/lichenni/projects/mobicom22_fl/training/learner.py", line 106, in init_myprocesses
    fn(rank, model, q, param_q, stop_flag, client_cfg)
  File "/mnt/home/lichenni/projects/mobicom22_fl/training/learner.py", line 679, in run
    queue.put({rank: [None, None, None, True, -1, -1]})
  File "<string>", line 2, in put
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/managers.py", line 756, in _callmethod
    conn.send((self._id, methodname, args, kwds))
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 206, in send
    self._send_bytes(_ForkingPickler.dumps(obj))
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 404, in _send_bytes
    self._send(header + buf)
  File "/mnt/home/lichenni/anaconda3/envs/oort/lib/python3.6/multiprocessing/connection.py", line 368, in _send
    n = write(self._handle, buf)
BrokenPipeError: [Errno 32] Broken pipe
