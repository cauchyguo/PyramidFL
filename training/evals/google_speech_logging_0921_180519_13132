2023-09-21:18:05:23,223 INFO     [param_server.py:14] End up with cuda device tensor([0.5416], device='cuda:0')
2023-09-21:18:05:23,673 INFO     [param_server.py:683] ====Start to initialize dataset
2023-09-21:18:05:23,674 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:18:05:52,726 INFO     [learner.py:13] End up with cuda device tensor([0.4272], device='cuda:3')
2023-09-21:18:05:52,727 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:18:05:52,970 INFO     [learner.py:13] End up with cuda device tensor([0.9663], device='cuda:2')
2023-09-21:18:05:52,970 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:18:05:53,4 INFO     [learner.py:13] End up with cuda device tensor([0.2733], device='cuda:1')
2023-09-21:18:05:53,5 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-21:18:05:53,173 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:18:05:53,173 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:18:05:53,409 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:18:05:53,409 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:18:05:53,449 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-21:18:05:53,449 INFO     [flLibs.py:74] ====Initialize the model
2023-09-21:18:05:55,27 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 3
2023-09-21:18:05:55,343 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 2
2023-09-21:18:05:55,579 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 1
2023-09-21:18:05:55,592 INFO     [distributed_c10d.py:319] Added key: store_based_barrier_key:1 to store for rank: 0
2023-09-21:18:05:55,593 INFO     [distributed_c10d.py:354] Rank 2: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:18:05:55,594 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:18:05:55,594 INFO     [distributed_c10d.py:354] Rank 0: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:18:05:55,599 INFO     [distributed_c10d.py:354] Rank 3: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:18:05:55,599 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:18:05:55,600 INFO     [distributed_c10d.py:354] Rank 1: Completed store-based barrier for key:store_based_barrier_key:1 with 4 nodes.
2023-09-21:18:05:55,601 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-21:18:05:55,618 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.02416682243347168 s

2023-09-21:18:05:55,618 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:18:05:55,625 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.023622512817382812 s

2023-09-21:18:05:55,625 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:18:05:55,626 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.02674579620361328 s

2023-09-21:18:05:55,626 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-21:18:05:57,243 INFO     [param_server.py:104] ====Info of all feasible clients {'total_feasible_clients': 491, 'total_length': 33443}
2023-09-21:18:05:57,516 INFO     [param_server.py:216] ====PS: get in run()
2023-09-21:18:05:57,518 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:18:05:57,518 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:18:05:57,519 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0003142356872558594 s

2023-09-21:18:05:57,519 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.00038170814514160156 s

2023-09-21:18:05:57,519 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:18:05:57,519 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:18:05:57,518 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-21:18:05:57,520 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:18:05:57,520 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:18:05:57,520 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0003943443298339844 s

2023-09-21:18:05:57,520 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-21:18:05:57,521 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-21:18:05:57,522 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:18:05:57,522 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:18:05:57,523 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:18:05:57,523 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:18:05:57,524 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-21:18:05:57,524 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-21:18:05:57,524 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:18:05:57,528 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:18:05:57,528 INFO     [learner.py:445] ====Worker: Start running
2023-09-21:18:05:57,602 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=1, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=59489, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='23068', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0921_180519_13132', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:18:05:57,603 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=2, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=59489, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='23068', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=2, threads=4, time_stamp='0921_180519_13132', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:18:05:57,619 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=3, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=59489, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='23068', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=3, threads=4, time_stamp='0921_180519_13132', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=10, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-21:18:05:57,809 INFO     [learner.py:526] ====Start train round 1
2023-09-21:18:05:57,810 INFO     [learner.py:526] ====Start train round 1
2023-09-21:18:05:57,816 INFO     [learner.py:526] ====Start train round 1
2023-09-21:18:05:57,963 INFO     [learner.py:164] Start to run client 2 on rank 2...
====Worker: init_myprocesses
Begin!
2023-09-21:18:05:57,970 INFO     [learner.py:164] Start to run client 6 on rank 3...
2023-09-21:18:05:57,972 INFO     [learner.py:164] Start to run client 1 on rank 1...
====Worker: init_myprocesses
Begin!
====Worker: init_myprocesses
Begin!
2023-09-21:18:06:00,670 INFO     [learner.py:437] ====Failed to run client 6
2023-09-21:18:06:00,670 INFO     [learner.py:439] Completed to run client 6
2023-09-21:18:06:00,671 INFO     [learner.py:606] ====Pushing takes 0.0008318424224853516 s
2023-09-21:18:06:00,672 INFO     [param_server.py:321] ====Start to merge models
2023-09-21:18:06:00,672 INFO     [param_server.py:399] ====Done handling rank 3, with ratio 0, now collected 0 clients
2023-09-21:18:06:00,673 INFO     [param_server.py:455] Lock worker 3 with localStep 1 , while globalStep is 0

2023-09-21:18:06:00,698 INFO     [learner.py:437] ====Failed to run client 2
2023-09-21:18:06:00,699 INFO     [learner.py:439] Completed to run client 2
2023-09-21:18:06:00,699 INFO     [learner.py:606] ====Pushing takes 0.0005967617034912109 s
2023-09-21:18:06:00,700 INFO     [param_server.py:321] ====Start to merge models
2023-09-21:18:06:00,700 INFO     [param_server.py:399] ====Done handling rank 2, with ratio 0, now collected 0 clients
2023-09-21:18:06:00,700 INFO     [param_server.py:455] Lock worker 2 with localStep 1 , while globalStep is 0

2023-09-21:18:06:01,29 INFO     [learner.py:437] ====Failed to run client 1
2023-09-21:18:06:01,30 INFO     [learner.py:439] Completed to run client 1
2023-09-21:18:06:01,31 INFO     [learner.py:606] ====Pushing takes 0.0008702278137207031 s
2023-09-21:18:06:01,31 INFO     [param_server.py:321] ====Start to merge models
2023-09-21:18:06:01,31 INFO     [param_server.py:399] ====Done handling rank 1, with ratio 0, now collected 0 clients
2023-09-21:18:06:01,32 INFO     [param_server.py:425] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 3.0
2023-09-21:18:06:01,32 INFO     [param_server.py:455] Lock worker 1 with localStep 1 , while globalStep is 1

2023-09-21:18:06:01,32 INFO     [param_server.py:486] ====Epoch 2 completes 0 clients with loss 0, sampled rewards are: 
 {} 
==========
2023-09-21:18:06:01,32 INFO     [param_server.py:495] ====Start to sample for epoch 2, global virtualClock: 0.0, round_duration: 0.0
2023-09-21:18:06:01,34 INFO     [param_server.py:513] ====Try to resample clients, final takes: 
 [1286, 38, 1835, 189, 1315, 348, 831, 140, 1510, 584]
2023-09-21:18:06:01,565 INFO     [param_server.py:633] ====Error: list index out of range, <class 'IndexError'>, param_server.py, 585
====Error: list index out of range

('list index out of range',)
===============
Traceback (most recent call last):
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 585, in run
    param.data += sumDeltaWeights[idx]
IndexError: list index out of range

Traceback (most recent call last):
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 691, in <module>
    
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 137, in init_myprocesses
    fn(model, queue, param_q, stop_signal, clientSampler)
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 294, in run
    if not queue.empty():
  File "<string>", line 2, in empty
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/managers.py", line 819, in _callmethod
    kind, result = conn.recv()
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/ypguo/.conda/envs/mytorch/lib/python3.7/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
