/home/ypguo/.conda/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2023-09-20:23:29:45,565 INFO     [param_server.py:13] End up with cuda device tensor([0.8563], device='cuda:0')
2023-09-20:23:29:46,25 INFO     [param_server.py:616] ====Start to initialize dataset
2023-09-20:23:29:46,25 INFO     [flLibs.py:59] ====Initialize the model
/home/ypguo/.conda/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2023-09-20:23:30:15,31 INFO     [learner.py:13] End up with cuda device tensor([0.5785], device='cuda:3')
2023-09-20:23:30:15,32 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
/home/ypguo/.conda/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2023-09-20:23:30:15,71 INFO     [learner.py:13] End up with cuda device tensor([0.7218], device='cuda:1')
2023-09-20:23:30:15,73 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
/home/ypguo/.conda/envs/oort/lib/python3.6/site-packages/librosa/util/decorators.py:9: NumbaDeprecationWarning: An import was requested from a module that has moved location.
Import of 'jit' requested from: 'numba.decorators', please update to use 'numba.core.decorators' or pin to Numba version 0.48.0. This alias will not be present in Numba version 0.50.0.
  from numba.decorators import jit as optional_jit
2023-09-20:23:30:15,172 INFO     [learner.py:13] End up with cuda device tensor([0.8571], device='cuda:2')
2023-09-20:23:30:15,173 INFO     [learner.py:41] ===== Experiment start on : user-Server=====
2023-09-20:23:30:15,477 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-20:23:30:15,477 INFO     [flLibs.py:59] ====Initialize the model
2023-09-20:23:30:15,517 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-20:23:30:15,517 INFO     [flLibs.py:59] ====Initialize the model
2023-09-20:23:30:15,617 INFO     [learner.py:709] ====Start to initialize dataset
2023-09-20:23:30:15,617 INFO     [flLibs.py:59] ====Initialize the model
2023-09-20:23:30:16,154 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-20:23:30:16,171 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.016026735305786133 s

2023-09-20:23:30:16,171 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-20:23:30:16,201 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-20:23:30:16,228 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.026919841766357422 s

2023-09-20:23:30:16,228 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-20:23:30:16,465 INFO     [learner.py:732] ==== Starting training data partitioner =====
2023-09-20:23:30:16,489 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.023291587829589844 s

2023-09-20:23:30:16,489 INFO     [learner.py:735] ==== Finished training data partitioner =====
2023-09-20:23:30:18,68 INFO     [param_server.py:98] ====Info of all feasible clients {'total_feasible_clients': 491, 'total_length': 33443}
2023-09-20:23:30:18,335 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-20:23:30:18,335 INFO     [param_server.py:197] ====PS: get in run()
2023-09-20:23:30:18,336 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0005550384521484375 s

2023-09-20:23:30:18,336 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-20:23:30:18,337 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-20:23:30:18,338 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-20:23:30:18,338 INFO     [learner.py:748] ==== Starting testing data partitioner =====
2023-09-20:23:30:18,339 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0005335807800292969 s

2023-09-20:23:30:18,339 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-20:23:30:18,339 INFO     [divide_data.py:95] ====Initiating DataPartitioner takes 0.0005548000335693359 s

2023-09-20:23:30:18,339 INFO     [learner.py:750] ==== Finished testing data partitioner =====
2023-09-20:23:30:18,340 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-20:23:30:18,340 INFO     [divide_data.py:388] ========= Start of Random Partition =========

2023-09-20:23:30:18,342 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-20:23:30:18,342 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-20:23:30:18,344 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-20:23:30:18,344 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-20:23:30:18,344 INFO     [divide_data.py:509] Raw class per worker is : array([[18., 27., 25., 25., 16., 15., 22., 12., 24., 18., 11., 22., 21.,
        16., 13., 17.,  9., 11., 20., 12.],
       [14., 15., 24., 20., 16., 21., 22., 14., 16., 24., 16., 21., 20.,
         9., 15., 28., 10.,  5., 28., 16.],
       [12., 12., 23., 21., 12., 33., 24., 13., 19., 31., 21., 16., 18.,
        12., 10., 18., 11.,  9., 21., 18.]])

2023-09-20:23:30:18,345 INFO     [divide_data.py:510] ========= End of Class/Worker =========

2023-09-20:23:30:18,346 INFO     [learner.py:445] ====Worker: Start running
2023-09-20:23:30:18,347 INFO     [learner.py:445] ====Worker: Start running
2023-09-20:23:30:18,348 INFO     [learner.py:445] ====Worker: Start running
2023-09-20:23:30:18,387 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=1, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=24765, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='20380', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=1, threads=4, time_stamp='0920_232940_37992', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=20, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-20:23:30:18,390 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=3, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=24765, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='20380', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=3, threads=4, time_stamp='0920_232940_37992', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=20, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-20:23:30:18,391 INFO     [learner.py:483] 
Namespace(adam_epsilon=1e-08, adaptive_epoch_beta=1, backend='nccl', batch_size=16, bidirectional=True, blacklist_max_len=0.3, blacklist_rounds=-1, block_size=64, cache_dir=None, capacity_bin=True, clf_block_size=100, client_path='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_device_capacity', clip_bound=0.98, clock_factor=6.092057761732853, conf_path='~/dataset/', config_name=None, cut_off_util=0.4, data_dir='/disk7T/ypguo/FedScale/benchmark/dataset/data/speech_commands/google_speech', data_mapfile='/disk7T/ypguo/FedScale/benchmark/dataset/speech_commands/clientDataMap', data_set='google_speech', decay_epoch=15.0, decay_factor=0.95, display_step=20, do_eval=False, do_train=False, dropout_high=0.6, dropout_low=0.1, dump_epoch=1000, duplicate_data=1, enable_adapt_local_epoch=False, enable_dropout=False, enable_importance=False, enable_obs_client=False, enable_obs_importance=False, enable_obs_local_epoch=False, enforce_random=False, epochs=1000, eval_all_checkpoints=False, eval_data_file='', eval_interval=10, eval_interval_prior=9999999, evaluate_during_training=False, exploration_alpha=0.3, exploration_decay=0.95, exploration_factor=0.9, exploration_min=0.2, filter_class=0, filter_less=30, filter_more=100000.0, finetune=False, fixed_clients=False, force_read=False, forward_pass=False, fp16=False, fp16_opt_level='O1', full_gradient_interval=20, gpu_device=2, gradient_accumulation_steps=1, gradient_policy='yogi', hetero_allocation='1.0-1.0-1.0-1.0-1.0-1.0', heterogeneity=1.0, hidden_layers=7, hidden_size=256, home_path='', input_dim=0, is_even_avg=True, job_name='google_speech', labels_path='labels.json', learners='1-2-3', learning_rate=0.04, line_by_line=False, load_epoch=1, load_model=False, load_time_stamp='0615_194942', local_rank=-1, log_path='/disk7T/ypguo/PyramidFL/training/evals', logging_steps=500, loss_decay=0.2, malicious_clients=0, manager_port=24765, max_grad_norm=1.0, max_iter_store=100, max_steps=-1, min_learning_rate=0.0001, mlm=True, mlm_probability=0.1, model='resnet34', model_avg=True, model_name_or_path=None, model_path=None, model_size=65536, model_type='', no_cuda=False, noise_dir=None, noise_factor=0, noise_max=0.5, noise_min=0.0, noise_prob=0.4, num_class=20, num_loaders=2, num_train_epochs=1.0, output_dim=0, output_dir=None, overcommit=1.3, overwrite_cache=False, overwrite_output_dir=False, pacer_delta=30.0, pacer_step=20, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, proxy_avg=False, proxy_mu=0.1, ps_ip='user-Server', ps_port='20380', read_models_path=False, release_cache=False, resampling_interval=1, rnn_type='lstm', round_penalty=2.0, round_threshold=40.0, run_all=False, sample_mode='random', sample_rate=16000, sample_seed=233, sample_window=5.0, sampler_path=None, save_path='./', save_steps=500, save_total_limit=None, score_mode='loss', seed=42, sequential='0', server_ip='', server_port='', should_continue=False, single_sim=0, skip_partition=False, sleep_up=0, spec_augment=False, speed_volume_perturb=False, stale_threshold=0, task='speech', test_bsz=128, test_interval=20, test_manifest='data/test_manifest.csv', test_only=False, test_ratio=1.0, test_train_data=False, this_rank=2, threads=4, time_stamp='0920_232940_37992', timeout=9999999, to_device='cuda', tokenizer_name=None, total_worker=20, train_data_file='', train_manifest='data/train_manifest.csv', upload_epoch=5, user_trace='/disk7T/ypguo/FedScale/benchmark/dataset/data/device_info/client_behave_trace', validate_interval=999999, vocab_tag_size=500, vocab_token_size=10000, warmup_steps=0, weight_decay=0.0, window='hamming', window_size=0.02, window_stride=0.01, yogi_beta=0.999, yogi_beta2=-1, yogi_eta=0.005, yogi_tau=0.001, zipf_alpha='5')

2023-09-20:23:30:18,706 INFO     [learner.py:526] ====Start train round 1
2023-09-20:23:30:18,722 INFO     [learner.py:526] ====Start train round 1
2023-09-20:23:30:18,733 INFO     [learner.py:526] ====Start train round 1
2023-09-20:23:30:18,824 INFO     [learner.py:164] Start to run client 1 on rank 1...
2023-09-20:23:30:18,825 INFO     [learner.py:164] Start to run client 6 on rank 3...
====Worker: init_myprocesses
Begin!
====Worker: init_myprocesses
Begin!
2023-09-20:23:30:18,843 INFO     [learner.py:164] Start to run client 2 on rank 2...
====Worker: init_myprocesses
Begin!
THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=8 : invalid device function
2023-09-20:23:30:19,662 INFO     [learner.py:403] ====Error: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED, <class 'RuntimeError'>, learner.py, 312
THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=8 : invalid device function
2023-09-20:23:30:19,722 INFO     [learner.py:403] ====Error: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED, <class 'RuntimeError'>, learner.py, 312
THCudaCheck FAIL file=/pytorch/aten/src/THC/THCGeneral.cpp line=383 error=8 : invalid device function
2023-09-20:23:30:19,762 INFO     [learner.py:403] ====Error: cuDNN error: CUDNN_STATUS_EXECUTION_FAILED, <class 'RuntimeError'>, learner.py, 312
2023-09-20:23:30:20,132 INFO     [learner.py:437] ====Failed to run client 6
2023-09-20:23:30:20,132 INFO     [learner.py:439] Completed to run client 6
2023-09-20:23:30:20,133 INFO     [learner.py:606] ====Pushing takes 0.0005185604095458984 s
2023-09-20:23:30:20,133 INFO     [param_server.py:298] ====Start to merge models
2023-09-20:23:30:20,134 INFO     [param_server.py:364] ====Done handling rank 3, with ratio 0, now collected 0 clients
2023-09-20:23:30:20,134 INFO     [param_server.py:418] Lock worker 3 with localStep 1 , while globalStep is 0

2023-09-20:23:30:20,257 INFO     [learner.py:437] ====Failed to run client 1
2023-09-20:23:30:20,257 INFO     [learner.py:439] Completed to run client 1
2023-09-20:23:30:20,258 INFO     [learner.py:606] ====Pushing takes 0.0006389617919921875 s
2023-09-20:23:30:20,258 INFO     [param_server.py:298] ====Start to merge models
2023-09-20:23:30:20,259 INFO     [param_server.py:364] ====Done handling rank 1, with ratio 0, now collected 0 clients
2023-09-20:23:30:20,259 INFO     [param_server.py:418] Lock worker 1 with localStep 1 , while globalStep is 0

2023-09-20:23:30:20,330 INFO     [learner.py:437] ====Failed to run client 2
2023-09-20:23:30:20,330 INFO     [learner.py:439] Completed to run client 2
2023-09-20:23:30:20,331 INFO     [learner.py:606] ====Pushing takes 0.000621795654296875 s
2023-09-20:23:30:20,331 INFO     [param_server.py:298] ====Start to merge models
2023-09-20:23:30:20,331 INFO     [param_server.py:364] ====Done handling rank 2, with ratio 0, now collected 0 clients
2023-09-20:23:30:20,332 INFO     [param_server.py:389] ====After aggregation in epoch: 0, virtual_clock: 0.0, top_1: : 0.0 % (0.0), top_5: : 0.0 % (0.0), test loss: 0.0, test len: 3.0
2023-09-20:23:30:20,332 INFO     [param_server.py:418] Lock worker 2 with localStep 1 , while globalStep is 1

2023-09-20:23:30:20,332 INFO     [param_server.py:449] ====Epoch 2 completes 0 clients with loss 0, sampled rewards are: 
 {} 
==========
2023-09-20:23:30:20,332 INFO     [param_server.py:458] ====Start to sample for epoch 2, global virtualClock: 0.0, round_duration: 0.0
2023-09-20:23:30:20,334 INFO     [param_server.py:475] ====Try to resample clients, final takes: 
 [1286, 7, 1035, 505, 38, 1835, 189, 1315, 1176, 87, 988, 371, 348, 831, 162, 140, 1510, 281, 584, 573]
2023-09-20:23:30:20,841 INFO     [param_server.py:575] ====Error: list index out of range, <class 'IndexError'>, param_server.py, 535
====Error: list index out of range

Traceback (most recent call last):
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 624, in <module>
    q, param_q, stop_signal, run, args.backend
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 130, in init_myprocesses
    fn(model, queue, param_q, stop_signal, clientSampler)
  File "/disk7T/ypguo/PyramidFL/training/param_server.py", line 273, in run
    if not queue.empty():
  File "<string>", line 2, in empty
  File "/home/ypguo/.conda/envs/oort/lib/python3.6/multiprocessing/managers.py", line 757, in _callmethod
    kind, result = conn.recv()
  File "/home/ypguo/.conda/envs/oort/lib/python3.6/multiprocessing/connection.py", line 250, in recv
    buf = self._recv_bytes()
  File "/home/ypguo/.conda/envs/oort/lib/python3.6/multiprocessing/connection.py", line 407, in _recv_bytes
    buf = self._recv(4)
  File "/home/ypguo/.conda/envs/oort/lib/python3.6/multiprocessing/connection.py", line 379, in _recv
    chunk = read(handle, remaining)
KeyboardInterrupt
